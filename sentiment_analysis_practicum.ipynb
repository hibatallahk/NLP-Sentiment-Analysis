{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_practicum.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRfiNCDxxXEbQJC62hMj1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hibatallahk/NLP-Sentiment-Analysis/blob/main/sentiment_analysis_practicum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSrbA4mQ9iPo"
      },
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "In order to determine the tonality of the text, let's use TF-IDF values as features.\n",
        "Sentiment analysis identifies emotionally-charged texts. This tool can be extremely useful in business when evaluating consumer reactions to a new product. A human would need several hours to analyze thousands of reviews. A computer will do the same in a couple of minutes.\n",
        "Sentiment analysis works by labeling text as positive or negative. Positive text is given a \"1\", and negative text is assigned a \"0\".\n",
        "\n",
        "### Task\n",
        "Train a logistic regression to determine the tonality of reviews. Use TF-IDF vectors for lemmatized reviews as features.\n",
        "The train part of the dataset is in the imdb_reviews_small_lemm_train.tsv file, the lemmatized reviews are in the review_lemm column (so you don't have to lemmatize reviews yourself), the target is in the pos column (0 - negative review, 1, - positive review).\n",
        "Use the trained classification model to determine the prediction results for the test sample of reviews from the imdb_reviews_small_lemm_test.tsv file. Save the predictions to the pos column. Save the table with results as an CSV file. Don't specify the file extension so that the platform accepts the file (for example, call it 'predictions').\n",
        "The model accuracy should be at least 0.82."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nti7ySoN93mD",
        "outputId": "4ec8cda0-8e08-4b65-c569-edaca90a24fc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf9PwR-hwMtk"
      },
      "source": [
        "train_set = pd.read_csv('imdb_reviews_small_lemm_train.tsv', sep='\\t')\n",
        "test_set = pd.read_csv('imdb_reviews_small_lemm_test.tsv', sep='\\t')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF4Itkis0Njh"
      },
      "source": [
        "stop_words = set(nltk_stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR2AeVFl0h_z"
      },
      "source": [
        "count_tf_idf = TfidfVectorizer(stop_words=stop_words)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u_G45_b050t"
      },
      "source": [
        "features_train = count_tf_idf.fit_transform(train_set['review_lemm'])\n",
        "features_test = count_tf_idf.transform(test_set['review_lemm'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UheGCWWd0t1T"
      },
      "source": [
        "target_train = train_set['pos']\n",
        "target_test = train_set['pos']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CjNig0iwNGO"
      },
      "source": [
        "model_lr = LogisticRegression(random_state=12345)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytc7Fjhj58ci",
        "outputId": "bc05f003-7f3e-4547-9423-08836311b849"
      },
      "source": [
        "model_lr.fit(features_train, target_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=12345, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PCJOhWf5-j4"
      },
      "source": [
        "predictions = model_lr.predict(features_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aij_bC6J0CV3"
      },
      "source": [
        "submission = pd.DataFrame({'pos': predictions})\n",
        "submission.to_csv('predictions')"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}